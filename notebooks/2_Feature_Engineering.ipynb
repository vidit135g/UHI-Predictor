{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset Loaded. Shape: (11229, 16)\n",
      "ğŸ“Œ Available Columns in Dataset: ['datetime', 'longitude', 'latitude', 'uhi_index', 'land_surface_temp', 'band1', 'band2', 'band3', 'band4', 'air_temp_at_surface_', 'relative_humidity_', 'avg_wind_speed_', 'wind_direction_', 'solar_flux_', 'nearest_building_lon', 'nearest_building_lat']\n",
      "âœ… Column Names Sanitized: ['datetime', 'longitude', 'latitude', 'uhi_index', 'land_surface_temp', 'band1', 'band2', 'band3', 'band4', 'air_temp_at_surface_', 'relative_humidity_', 'avg_wind_speed_', 'wind_direction_', 'solar_flux_', 'nearest_building_lon', 'nearest_building_lat']\n",
      "âœ… Extracted Temporal Features: 'hour', 'weekday', 'month'\n",
      "âœ… Haversine Distance Calculated!\n",
      "âœ… Wind Direction Categorized!\n",
      "âœ… Created `hour_category` for time-based analysis.\n",
      "âœ… Encoder saved at models/encoder.pkl\n",
      "âœ… Categorical Features Encoded Successfully!\n",
      "âœ… Processed Data Saved: ../data/processed/UHI_Weather_Building_Sentinel_LST_Featured_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Feature Engineering Script\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from haversine import haversine\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ----------------- 1ï¸âƒ£ Load & Preprocess Data -----------------\n",
    "file_path = \"../data/processed/UHI_Weather_Building_Sentinel_LST_Merged.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"âœ… Dataset Loaded. Shape: {df.shape}\")\n",
    "\n",
    "# **Print Available Columns Before Processing**\n",
    "print(\"ğŸ“Œ Available Columns in Dataset:\", df.columns.tolist())\n",
    "\n",
    "# **Sanitize column names (remove special characters, lowercase)**\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(r\"[^\\w\\s]\", \"_\", regex=True)\n",
    "print(\"âœ… Column Names Sanitized:\", df.columns.tolist())\n",
    "\n",
    "# ----------------- 2ï¸âƒ£ Extract Temporal Features -----------------\n",
    "if \"datetime\" in df.columns:\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "    df[\"weekday\"] = df[\"datetime\"].dt.weekday\n",
    "    df[\"month\"] = df[\"datetime\"].dt.month\n",
    "    df.drop(columns=[\"datetime\"], inplace=True)  # Remove original datetime column\n",
    "    print(\"âœ… Extracted Temporal Features: 'hour', 'weekday', 'month'\")\n",
    "\n",
    "# ----------------- 3ï¸âƒ£ Calculate Haversine Distance -----------------\n",
    "# Ensure required columns exist\n",
    "required_columns = [\"latitude\", \"longitude\", \"nearest_building_lat\", \"nearest_building_lon\"]\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"âŒ Missing required column: {col}\")\n",
    "\n",
    "# Function to calculate distance from nearest building\n",
    "def calculate_haversine_distance(row):\n",
    "    return haversine(\n",
    "        (row[\"latitude\"], row[\"longitude\"]),\n",
    "        (row[\"nearest_building_lat\"], row[\"nearest_building_lon\"])\n",
    "    )\n",
    "\n",
    "df[\"building_distance_m\"] = df.apply(calculate_haversine_distance, axis=1)\n",
    "print(\"âœ… Haversine Distance Calculated!\")\n",
    "\n",
    "# ----------------- 4ï¸âƒ£ Categorize Wind Direction -----------------\n",
    "# Function to classify wind direction\n",
    "def categorize_wind_direction(degrees):\n",
    "    if 0 <= degrees < 90:\n",
    "        return \"North-East\"\n",
    "    elif 90 <= degrees < 180:\n",
    "        return \"South-East\"\n",
    "    elif 180 <= degrees < 270:\n",
    "        return \"South-West\"\n",
    "    else:\n",
    "        return \"North-West\"\n",
    "\n",
    "wind_direction_col = [col for col in df.columns if \"wind_direction\" in col.lower()]\n",
    "if wind_direction_col:\n",
    "    df[\"wind_direction_category\"] = df[wind_direction_col[0]].apply(categorize_wind_direction)\n",
    "    print(\"âœ… Wind Direction Categorized!\")\n",
    "\n",
    "# ----------------- 5ï¸âƒ£ Categorize Time of Day -----------------\n",
    "df[\"hour_category\"] = pd.cut(\n",
    "    df[\"hour\"],\n",
    "    bins=[0, 6, 12, 18, 24],\n",
    "    labels=[\"Night\", \"Morning\", \"Afternoon\", \"Evening\"],\n",
    "    include_lowest=True,\n",
    ")\n",
    "print(\"âœ… Created `hour_category` for time-based analysis.\")\n",
    "\n",
    "# ----------------- 6ï¸âƒ£ One-Hot Encoding for Categorical Features -----------------\n",
    "categorical_columns = [\"hour_category\", \"wind_direction_category\"]\n",
    "\n",
    "# âœ… One-Hot Encoding\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# âœ… Save the encoder for later use in predictions\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(encoder, \"models/encoder.pkl\")\n",
    "print(\"âœ… Encoder saved at models/encoder.pkl\")\n",
    "\n",
    "# Drop original categorical columns & Concatenate encoded ones\n",
    "df = df.drop(columns=categorical_columns).reset_index(drop=True)\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "print(\"âœ… Categorical Features Encoded Successfully!\")\n",
    "\n",
    "# ----------------- 7ï¸âƒ£ Feature Selection -----------------\n",
    "# âœ… Drop Unused Columns\n",
    "unused_cols = [\"nearest_building_lon\", \"nearest_building_lat\"]\n",
    "df = df.drop(columns=[col for col in unused_cols if col in df.columns], errors=\"ignore\")\n",
    "\n",
    "# Ensure all features are numeric before training\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        print(f\"âš ï¸ Non-numeric column detected: {col} (Dropping)\")\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# ----------------- 8ï¸âƒ£ Save Processed Data -----------------\n",
    "processed_path = \"../data/processed/UHI_Weather_Building_Sentinel_LST_Featured_Cleaned.csv\"\n",
    "df.to_csv(processed_path, index=False)\n",
    "print(f\"âœ… Processed Data Saved: {processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 datetime64[ns]\n",
       "longitude                       float64\n",
       "latitude                        float64\n",
       "uhi_index                       float64\n",
       "land_surface_temp               float64\n",
       "band1                           float64\n",
       "band2                           float64\n",
       "band3                           float64\n",
       "band4                           float64\n",
       "air_temp_at_surface_            float64\n",
       "relative_humidity_              float64\n",
       "avg_wind_speed_                 float64\n",
       "wind_direction_                 float64\n",
       "solar_flux_                     float64\n",
       "nearest_building_lon            float64\n",
       "nearest_building_lat            float64\n",
       "building_distance_m             float64\n",
       "building_density_50m              int64\n",
       "building_density_100m             int64\n",
       "building_density_200m             int64\n",
       "hour                              int32\n",
       "weekday                           int32\n",
       "month                             int32\n",
       "hour_category                  category\n",
       "is_weekend                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 0\n",
       "longitude                0\n",
       "latitude                 0\n",
       "uhi_index                0\n",
       "land_surface_temp        0\n",
       "band1                    0\n",
       "band2                    0\n",
       "band3                    0\n",
       "band4                    0\n",
       "air_temp_at_surface_     0\n",
       "relative_humidity_       0\n",
       "avg_wind_speed_          0\n",
       "wind_direction_          0\n",
       "solar_flux_              0\n",
       "nearest_building_lon     0\n",
       "nearest_building_lat     0\n",
       "building_distance_m      0\n",
       "building_density_50m     0\n",
       "building_density_100m    0\n",
       "building_density_200m    0\n",
       "hour                     0\n",
       "weekday                  0\n",
       "month                    0\n",
       "hour_category            0\n",
       "is_weekend               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
