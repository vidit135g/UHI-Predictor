{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models and Scaler Loaded Successfully\n",
      "✅ Loaded Submission Data. Shape: (1040, 3)\n",
      "📌 Available Columns: ['Longitude', 'Latitude', 'UHI Index']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Sentinel-2 Data: 100%|██████████| 1040/1040 [00:01<00:00, 955.60it/s]\n",
      "/var/folders/y0/slhcnc5d5ylcv5sf0glxtrvr0000gn/T/ipykernel_81741/3133153453.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sentinel_features[\"NDVI\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Missing Feature: land_surface_temp. Filling with default value 0...\n",
      "⚠️ Missing Feature: band1. Filling with default value 0...\n",
      "⚠️ Missing Feature: band2. Filling with default value 0...\n",
      "⚠️ Missing Feature: band3. Filling with default value 0...\n",
      "⚠️ Missing Feature: band4. Filling with default value 0...\n",
      "⚠️ Missing Feature: air_temp_at_surface_. Filling with default value 0...\n",
      "⚠️ Missing Feature: relative_humidity_. Filling with default value 0...\n",
      "⚠️ Missing Feature: avg_wind_speed_. Filling with default value 0...\n",
      "⚠️ Missing Feature: wind_direction_. Filling with default value 0...\n",
      "⚠️ Missing Feature: solar_flux_. Filling with default value 0...\n",
      "⚠️ Missing Feature: hour. Filling with default value 0...\n",
      "⚠️ Missing Feature: weekday. Filling with default value 0...\n",
      "⚠️ Missing Feature: month. Filling with default value 0...\n",
      "⚠️ Missing Feature: building_distance_m. Filling with default value 0...\n",
      "⚠️ Missing Feature: hour_category_afternoon. Filling with default value 0...\n",
      "⚠️ Missing Feature: wind_direction_category_south_east. Filling with default value 0...\n",
      "⚠️ Missing Feature: wind_direction_category_south_west. Filling with default value 0...\n",
      "🚨 Feature Mismatch Error: The feature names should match those that were passed during fit.\n",
      "Feature names unseen at fit time:\n",
      "- air_temp_at_surface_\n",
      "- avg_wind_speed_\n",
      "- band1\n",
      "- band2\n",
      "- band3\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Air Temp at Surface [degC]\n",
      "- Altitude\n",
      "- Avg Wind Speed [m/s]\n",
      "- Latitude\n",
      "- Longitude\n",
      "- ...\n",
      "\n",
      "⚠️ Skipping Scaling to Debug Feature Issue...\n",
      "✅ Submission File Created: ../data/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 📌 Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import rioxarray as rxr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ Load Trained Models & Preprocessors\n",
    "rf_model = joblib.load(\"../models/rf_model.pkl\")\n",
    "xgb_model = joblib.load(\"../models/xgb_model.pkl\")\n",
    "scaler = joblib.load(\"../models/scaler.pkl\")\n",
    "feature_names = joblib.load(\"../models/feature_names.pkl\")  # Expected feature names\n",
    "\n",
    "print(\"✅ Models and Scaler Loaded Successfully\")\n",
    "\n",
    "# 📌 Load Submission Data\n",
    "submission_data = pd.read_csv(\"../data/raw/Submission_template.csv\")\n",
    "print(f\"✅ Loaded Submission Data. Shape: {submission_data.shape}\")\n",
    "print(\"📌 Available Columns:\", submission_data.columns.tolist())\n",
    "\n",
    "# 📌 Sentinel-2 GeoTIFF Path\n",
    "tiff_path = \"../data/raw/S2_sample.tiff\"\n",
    "\n",
    "# ✅ Extract Band Features from GeoTIFF\n",
    "def extract_band_values(tiff_path, csv_data):\n",
    "    \"\"\"Extract Sentinel-2 band values from a GeoTIFF based on Lat/Lon coordinates.\"\"\"\n",
    "    data = rxr.open_rasterio(tiff_path)\n",
    "    band_values = { \"B01\": [], \"B06\": [], \"B08\": [] }\n",
    "\n",
    "    for lat, lon in tqdm(zip(csv_data[\"Latitude\"], csv_data[\"Longitude\"]), total=len(csv_data), desc=\"Extracting Sentinel-2 Data\"):\n",
    "        try:\n",
    "            b01 = float(data.sel(x=lon, y=lat, band=1, method=\"nearest\").values)\n",
    "            b06 = float(data.sel(x=lon, y=lat, band=3, method=\"nearest\").values)\n",
    "            b08 = float(data.sel(x=lon, y=lat, band=4, method=\"nearest\").values)\n",
    "\n",
    "            band_values[\"B01\"].append(b01)\n",
    "            band_values[\"B06\"].append(b06)\n",
    "            band_values[\"B08\"].append(b08)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error at ({lat}, {lon}): {e}\")\n",
    "            band_values[\"B01\"].append(np.nan)\n",
    "            band_values[\"B06\"].append(np.nan)\n",
    "            band_values[\"B08\"].append(np.nan)\n",
    "\n",
    "    return pd.DataFrame(band_values)\n",
    "\n",
    "# 🔍 Extract Features\n",
    "sentinel_features = extract_band_values(tiff_path, submission_data)\n",
    "\n",
    "# ✅ Compute NDVI (Normalized Difference Vegetation Index)\n",
    "sentinel_features[\"NDVI\"] = (sentinel_features[\"B08\"] - sentinel_features[\"B01\"]) / (sentinel_features[\"B08\"] + sentinel_features[\"B01\"])\n",
    "sentinel_features[\"NDVI\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# ✅ Merge Extracted Features into Submission Data\n",
    "submission_data = pd.concat([submission_data, sentinel_features], axis=1)\n",
    "\n",
    "# 📌 **Standardize Column Names**\n",
    "submission_data.columns = submission_data.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# ✅ **Ensure Matching Feature Names Before Scaling**\n",
    "expected_features = [col.lower().replace(\" \", \"_\") for col in feature_names]\n",
    "\n",
    "# ✅ **Handle Missing Features**\n",
    "for col in expected_features:\n",
    "    if col not in submission_data.columns:\n",
    "        print(f\"⚠️ Missing Feature: {col}. Filling with default value 0...\")\n",
    "        submission_data[col] = 0  # Default fill for missing columns\n",
    "\n",
    "# ✅ **Align Columns & Ensure Correct Order**\n",
    "submission_features = submission_data[expected_features]  \n",
    "\n",
    "# 📌 **Apply Standard Scaling**\n",
    "try:\n",
    "    scaled_features = scaler.transform(submission_features)\n",
    "except ValueError as e:\n",
    "    print(\"🚨 Feature Mismatch Error:\", e)\n",
    "    print(\"⚠️ Skipping Scaling to Debug Feature Issue...\")\n",
    "    scaled_features = submission_features.to_numpy()  # Bypass scaling temporarily\n",
    "\n",
    "# ✅ Convert to DataFrame & Align with Feature Names\n",
    "submission_final = pd.DataFrame(scaled_features, columns=feature_names)\n",
    "\n",
    "# 📌 Make Predictions using Trained Models\n",
    "rf_predictions = rf_model.predict(submission_final)\n",
    "xgb_predictions = xgb_model.predict(submission_final)\n",
    "\n",
    "# 📌 Aggregate Predictions (Ensemble)\n",
    "final_predictions = (rf_predictions + xgb_predictions) / 2\n",
    "\n",
    "# 📌 Create Submission File\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Longitude\": submission_data[\"longitude\"],\n",
    "    \"Latitude\": submission_data[\"latitude\"],\n",
    "    \"UHI Index\": final_predictions.round(5)  # ✅ Round UHI Index to 5 decimal places\n",
    "})\n",
    "\n",
    "# ✅ Save Submission File\n",
    "submission_path = \"../data/submission.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"✅ Submission File Created: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
